{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2d0ebda-3d30-4536-b982-55946f8a06e2",
   "metadata": {},
   "source": [
    "# 自定义层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a0c778-75b0-4bbd-ba2f-8f5d1781af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd85440-2964-4a9a-bf2b-d9f4157fb8b1",
   "metadata": {},
   "source": [
    "### 不带参数的层\n",
    "构建一个**没有任何参数**的自定义层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a94d2c7-7d73-45bb-9f13-2056a52af8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X - X.mean()\n",
    "\n",
    "\n",
    "layer = CenteredLayer()\n",
    "layer(torch.FloatTensor([1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4735d5a5-7859-44e2-bb8b-a3e60f6c3b7d",
   "metadata": {},
   "source": [
    "将层作为组件**合并到构建更复杂的模型中**\n",
    "- 因为存储精度的原因，仍然可能会看到一个非常小的非零数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deeadaac-3eda-4812-bd2a-430260ace24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-6.2282e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())\n",
    "\n",
    "Y = net(torch.rand(4, 8))\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b653c6-54e2-4121-9576-aa11f5aea899",
   "metadata": {},
   "source": [
    "### 带参数的图层\n",
    "实现**自定义版本的全连接层**，需要两个参数——一个用来表示**权重**，一个用来表示**偏置项**\n",
    "- `dense = MyLinear(5, 3) `得到了一个`MyLinear`的实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa5d9f48-9af7-4b66-b4c7-0e0f6d9b858e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.3745,  0.8938, -1.3152],\n",
       "        [-0.2532, -0.2514, -2.2754],\n",
       "        [ 0.6998, -0.2958, -0.5224],\n",
       "        [ 0.0787,  1.4705,  0.4032],\n",
       "        [ 1.2067,  0.2011,  0.4960]], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.rand(units))\n",
    "\n",
    "    def forward(self, X):\n",
    "        linear = torch.mm(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)\n",
    "\n",
    "dense = MyLinear(5, 3) \n",
    "dense.weight        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25ac76b-58a8-4ccc-85c3-2588e97371eb",
   "metadata": {},
   "source": [
    "**使用自定义层直接执行正向传播计算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c56d2da2-36e9-4ccd-b1bd-f9ed616a0dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4242, 2.3293, 0.0000],\n",
       "        [1.6959, 2.4471, 0.0000]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense(torch.rand(2, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277bcbd-c16b-4072-9bd7-d99d62063ca3",
   "metadata": {},
   "source": [
    "**使用自定义的层构建模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7eab388-d599-4128-aa9a-9efd106d38b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5184],\n",
       "        [-0.9763]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(MyLinear(64, 8), nn.Linear(8, 1))\n",
    "net(torch.rand(2, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b2453-b95c-4c8d-a09d-d500584d4b0a",
   "metadata": {},
   "source": [
    "### 小结\n",
    "\n",
    "* 我们可以通过基本层类设计自定义层。这允许我们定义灵活的新层，其行为与深度学习框架中的任何现有层不同。\n",
    "* 在自定义层定义完成后，我们就可以在任意环境和网络架构中调用该自定义层。\n",
    "* 层可以有局部参数，这些参数可以通过内置函数创建。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b31a55-fb1a-4012-b658-bfc80ac79f8e",
   "metadata": {},
   "source": [
    "### 练习\n",
    "1. 设计一个接受输入并计算张量降维的层，它返回$y_k = \\sum_{i, j} W_{ijk} x_i x_j$。\n",
    "- `.diagonal()`是pytorch中用于提取矩阵或张量**对角线元素**的方法\n",
    "    - 取矩阵乘法得到的**矩阵的对角线元素**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7f431ca-eaad-4a2e-8a57-b9003e5f6be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TensorReduction(nn.Module):\n",
    "    def __init__(self, dim1, dim2):\n",
    "        super().__init__()\n",
    "        # 定义一个可训练的权重参数，维度为(dim2, dim1, dim1)\n",
    "        self.weight = nn.Parameter(torch.rand(dim2, dim1, dim1))\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 初始化一个全零张量，大小为(X.shape[0], self.weight.shape[0])\n",
    "        Y = torch.zeros(X.shape[0], self.weight.shape[0])\n",
    "        for k in range(self.weight.shape[0]):\n",
    "            # 计算temp = X @ weight[k] @ X^T\n",
    "            temp = X @ self.weight[k] @ X.T\n",
    "            # 取temp的对角线元素，存入Y[:, k]\n",
    "            Y[:, k] = temp.diagonal()\n",
    "        return Y\n",
    "\n",
    "layer = TensorReduction(10, 5)\n",
    "X = torch.rand(2, 10)\n",
    "layer(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5658eb72-3868-49a9-af91-4a9254bc3121",
   "metadata": {},
   "source": [
    "2. 设计一个返回输入数据的傅立叶系数前半部分的层。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fac383-9199-4f20-b419-1476dbc5c327",
   "metadata": {},
   "source": [
    "- `torch.fft`模块用于计算张量的傅立叶变换及操作\n",
    "    - `torch.fft.fft(input, dim=-1)`计算输入张量的离散傅里叶变换\n",
    "    - `torch.fft.ifft(input, dim=-1)`计算傅里叶变换的逆变换\n",
    "    - ...\n",
    "- `X = X[..., :X.shape[-1] // 2]`其中`...`表示**除最后一个维度以外**的所有维度不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed7deb4f-145b-4a04-85c4-b02a295bf54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 100, 50])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn, fft\n",
    "\n",
    "class FourierLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 先傅里叶变换\n",
    "        X = fft.fftn(X)\n",
    "        X = X[..., :X.shape[-1] // 2]\n",
    "        return X\n",
    "\n",
    "X = torch.rand(20, 100, 100)\n",
    "net = FourierLayer()\n",
    "net(X).shape\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472f85d5-6b0c-4a1c-a02e-6a5f001f5ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae196685-606d-45c7-8af5-2339ef7a1f48",
   "metadata": {},
   "source": [
    "# 读写文件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fdbf16-76a8-411c-9278-4949fc03d87b",
   "metadata": {},
   "source": [
    "### 加载和保存张量\n",
    "- 对单个张量，可以直接调用`load`和`save`来读写，都**要求提供一个名称**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6029888e-19cd-411b-b6aa-967ed09a0a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "885c25cd-1a58-4096-9ce6-cda9fee5b2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "torch.save(x, 'x-file')   # 保存在当前目录下\n",
    "\n",
    "x1 = torch.load('x-file', weights_only=True)\n",
    "x1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4230b9-6fb7-4e4f-ad4c-f0ec697fcd31",
   "metadata": {},
   "source": [
    "存储一个**张量*列表***，将其读回内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4cf4276-24b2-4423-8c1b-ed854f85428a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros(4)\n",
    "torch.save([x, y], 'x-files')\n",
    "x2, y2 = torch.load('x-files', weights_only=True)\n",
    "(x2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44b850d-8d76-4686-8d04-79322e6bd684",
   "metadata": {},
   "source": [
    "写入或读取**从字符串映射到张量的*字典***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7801652f-25cd-46d8-b97c-a266061459c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x': x, 'y': y}\n",
    "torch.save(mydict, 'mydict')\n",
    "mydict1 = torch.load('mydict', weights_only=True)\n",
    "mydict1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ec5b57-6c3e-484e-b048-e8e565083792",
   "metadata": {},
   "source": [
    "### 加载和保存模型参数\n",
    "- 模型本身可以包含任意代码，故模型本身难以序列化\n",
    "- 需要**用代码生成架构**，然后**从磁盘加载参数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f81898a-ebea-495e-9836-db4fb6e02cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.output(F.relu(self.hidden(X)))\n",
    "\n",
    "X = torch.rand(2, 20)\n",
    "net = MLP()\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae595ae7-6852-4485-b2e8-286855cc4a3a",
   "metadata": {},
   "source": [
    "将**模型的参数储存为一个叫做‘mlp.params’的文件**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f192a2ff-43ff-4800-a1bb-448f37d03b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'mlp.params')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e58b92-5ab3-48df-bb74-23f4a9b9e12a",
   "metadata": {},
   "source": [
    "#### **实例化了原始多层感知机模型的一个备份**，直接读取文件中存储的参数\n",
    "- 从存储的文件中**加载了一个多层感知机的参数**\n",
    "- 然后**将这些参数加载到一个新的`MLP`模型实例中**，实现模型的恢复"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8122c2e-6939-4157-a011-b3542c53d8dc",
   "metadata": {},
   "source": [
    "- `.load_state_dict()`：方法会将模型的所有参数用加载的参数文件**替换**，故**无需重新初始化模型参数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "085a081a-fb4d-4595-aebf-37313dac3d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params', weights_only=True))\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b7c0de-e527-429e-b59f-a59b8cd1b03c",
   "metadata": {},
   "source": [
    "由于两个实例**具有相同的模型参数**，在输入相同的`X`时，两个实例的**计算结果应该相同**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06babecb-a20b-40f3-a188-00d5c5b413f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abf5fdd-da82-4ebf-a0f8-b934090cce14",
   "metadata": {},
   "source": [
    "### 小结\n",
    "\n",
    "* `save`和`load`函数可用于张量对象的文件读写。\n",
    "* 我们可以通过参数字典保存和加载网络的全部参数。\n",
    "* **保存架构必须*在代码中*完成**，而不是在参数中完成。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036474be-d6ae-43e9-b8df-63affcf67c84",
   "metadata": {},
   "source": [
    "### 练习\n",
    "1. 即使不需要将经过训练的模型部署到不同的设备上，存储模型参数还有什么实际的好处？\n",
    "- **加速模型训练**：可以闭麦每次重新训练模型时需重复计算之前已经计算过的权重和偏置\n",
    "- **节省内存空间**：比保存完整的模型文件更加节省内存空间\n",
    "- **便于共享和复现**\n",
    "- **便于调试和分析**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed68c3-9bf5-4d88-b2c9-abf39176bbad",
   "metadata": {},
   "source": [
    "2. 假设我们只想复用网络的一部分，以将其合并到不同的网络架构中。比如想在一个新的网络中使用之前网络的前两层，该怎么做？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a57dad3-6837-460b-a224-3deafe6a21a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2af40a7a-de8e-454b-a50f-8d06978fb2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        ...,\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# 原先的就用前面定义好的 `MLP`\n",
    "\n",
    "class MLP_new(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "torch.save(net.hidden.state_dict(), 'mlp.hidden.params')\n",
    "clone = MLP_new()\n",
    "clone.hidden.load_state_dict(torch.load('mlp.hidden.params', weights_only=True))\n",
    "print(clone.hidden.weight == net.hidden.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8649442-7e1a-438b-9cb5-4ef777ef6f2d",
   "metadata": {},
   "source": [
    "3. 如何同时保存网络架构和参数？需要对架构加上什么限制？\n",
    "- **不包含动态构造的层**，即不包含任何随机性质的操作，如dropout层的随机丢弃率应该是固定的\n",
    "- 网络架构需要再定义模型的文件中**可用**：pytorch会在加载模型时查找构建该模型的类定义\n",
    "    - 在加载完整模型的文件中，**引入构建模型的类定义**，如`from my_model_file import MLP`\n",
    "- **注意**：在加载文件时显示指定`weights_only=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0f4ef72-22b4-4028-93f6-e6dc4328bbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "net = MLP()\n",
    "torch.save(net, 'model_complete.pt')\n",
    "net_loaded = torch.load('model_complete.pt', weights_only=False)\n",
    "net_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020293a7-eef8-42a9-b957-4a5ed4b0caed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
