{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c008d439-8699-4102-96ef-1fdc4dde783f",
   "metadata": {},
   "source": [
    "### 确保电脑里有GPU\n",
    "- `!nvidia-smi`：可以看到GPU的使用率（查看**显卡信息**）\n",
    "- 在pytorch中，**每个数组都有一个设备**（device），通常称其为环境（context）\n",
    "- 所有深度学习框架默认所有变量和相关的计算都分配给CPU——**要指定去GPU上**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf95fa98-3d0a-4621-a1d0-9e1a383abe16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 28 09:55:41 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 457.49       Driver Version: 457.49       CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce MX150      WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   51C    P0    N/A /  N/A |    505MiB /  2048MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     16648      C   ...\\envs\\fxr_env2\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6b61aa-61de-4d88-8e5f-249ff9794442",
   "metadata": {},
   "source": [
    "### 计算设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b8582d4-c69f-474e-9050-7be34311e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d14a487-6007-4ed1-9e74-b9fbb678d880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'), <torch.cuda.device at 0x2ee3e11b9d0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cpu'), torch.cuda.device('cuda') #, torch.cuda.device('cuda:1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4597b0a-f195-4a08-b399-62d7eff7b756",
   "metadata": {},
   "source": [
    "**查询可用GPU的数量**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da5ef025-bccc-4c6e-b416-678e2ebb9cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90e86d09-1810-49dc-a887-b1b8270e9d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4abba0d-ab5f-4fc4-8110-64822fa25681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b51832-031c-499d-9c83-8dbcdf0a6813",
   "metadata": {},
   "source": [
    "以下两个函数**允许在请求的GPU不存在的情况下运行代码**\n",
    "- `torch.cuda.device('cuda')`\n",
    "- `torch.device(f'cuda:{i}')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20f6d8c4-7a7d-4be2-9f96-4f6fba45440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu(i=0):\n",
    "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        # return torch.cuda.device('cuda')\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "def try_all_gups():\n",
    "    \"\"\"返回所有可用的GPU，如果没有GPU，则返回[cpu(),]\"\"\"\n",
    "    devices = [\n",
    "        torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())\n",
    "    ]\n",
    "    return devices if devices else [torch.decive('cpu')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77795b10-4baa-4457-9b65-3e2df3389f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 \n",
      " cpu \n",
      " [device(type='cuda', index=0)]\n"
     ]
    }
   ],
   "source": [
    "print(try_gpu(),'\\n', try_gpu(3), '\\n', try_all_gups())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc05d49-380a-47a9-b015-b8a5483b8d1e",
   "metadata": {},
   "source": [
    "### 张量和GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0457cbdd-7a74-4a70-9569-5502f1f9eff4",
   "metadata": {},
   "source": [
    "查询**张量所在的设备**，默认情况下，张量是在CPU上创建的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1b5fa0b-ef62-481a-a4e6-3d7d65797182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5a9fee-e7ef-40a0-b37d-1ce8fbf3f94e",
   "metadata": {},
   "source": [
    "### 存储在GPU上\n",
    "- 一般来说，需要保证不创建超过GPU显存限制的数据\n",
    "- `device=try_gpu(i)`，其中`i`可以填成GPU的index数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "054ce19d-ce2d-4740-89d1-6ef7b514793a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.]], device='cuda:0'),\n",
       " tensor([[0.0615, 0.2499, 0.6369],\n",
       "         [0.7280, 0.2063, 0.2898]], device='cuda:0'))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2, 3, device=try_gpu())\n",
    "y = torch.rand(2, 3, device=try_gpu())\n",
    "# y = torch.rand(2, 3, device=try_gpu(1))\n",
    "x , y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6721928c-e4c1-4356-81f8-8cd94df4e17a",
   "metadata": {},
   "source": [
    "#### 运算涉及的变量必须在**同一个GPU上**才可以在GPU上运算\n",
    "- GPU数据挪到CPU是**很慢**的——**出于性能的考虑**\n",
    "- **在设备（CPU、GPU和其他机器）之间传递数据比计算慢得多**——使得并行化变得更加困难"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82372cb1-c6d2-4bd5-af90-edea79bfbf4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0615, 1.2499, 1.6369],\n",
       "        [1.7280, 1.2063, 1.2898]], device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z = y.cuda(0)\n",
    "# x + z\n",
    "x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69da964c-cd7a-4597-be6b-00b14a2f2a24",
   "metadata": {},
   "source": [
    "### 神经网络和GPU\n",
    "- `net.to(device=try_gpu())`——`Module`**只能**用`to(device=)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63087126-a84a-4b48-9180-a635ba66da52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7511],\n",
       "        [0.7511]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(3, 1))\n",
    "net = net.to(device=try_gpu())\n",
    "\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8fa487-3978-416c-8fec-5485fb973306",
   "metadata": {},
   "source": [
    "**确认模型、参数存储在同一GPU上**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f93ffb3-aa1d-47f0-a360-976be4efc1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5738b2-bfde-41a7-ae86-330436989250",
   "metadata": {},
   "source": [
    "#### 在GPU上做运算的**办法**：\n",
    "将数据挪到GPU上，则对应的操作也会在GPU上完成\n",
    "- 需要手动copy到GPU上，若有多个GPU，需要保证数据在同一GPU上做运行\n",
    "- 对于神经网络也是一样，需要将权重copy到GPU上，输入也copy到GPU上，就可以在GPU上forward，backward也会在同一GPU上做运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ce7fae-11d1-4297-9da2-1cee1c38d487",
   "metadata": {},
   "source": [
    "- data preprocessing在GPU上不一定支持的比较好\n",
    "- 在深度学习中，当在GPU上计算数据（比如张量）后，如果想要**在Python中打印该张量的值或将其转换为NumPy数组进行进一步处理**——需要将数据从**GPU内存**复制到**CPU内存**\n",
    "    - 这一过程涉及数据传输，会带来**额外的传输时间开销**\n",
    "    - **全局解释器锁（GIL）**：Python的解释器使用这个机制，确保只有一个线程可以同时执行Python字节码\n",
    "        - 会导致串行化的效果，尤其是多线程环境下，因为Python会阻塞其他线程，直到当前线程完成\n",
    "        - 这种串行化对GPU到CPU的传输操作影响很大，因为所有相关的代码和线程都必须等待GIL释放\n",
    "        - 当频繁把**数据传到CPU并在Python环境中记录**（如转换为`ndarray`或打印输出），每次数据传输操作都会触发GIL\n",
    "    - **更好的实践**：避免频繁、细粒度的GPU到CPU传输\n",
    "        - 如：把日志记录的内存分配在GPU上，等一段时间或累积一定量后，再把这些数据批量传输到CPU，从而减少传输次数和对GIL的干扰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952051fb-ae2b-49e9-8af8-bf015df8ed67",
   "metadata": {},
   "source": [
    "### 小结\n",
    "\n",
    "* 我们可以指定用于存储和计算的设备，例如CPU或GPU。**默认情况下**，数据在主内存中创建，然后使用CPU进行计算。\n",
    "* 深度学习框架要求计算的**所有输入数据都在同一设备上**，无论是CPU还是GPU。\n",
    "* 不经意地移动数据可能会**显著降低性能**。一个典型的错误如下：计算GPU上每个小批量的损失，并在命令行中将其报告给用户（或将其记录在NumPy `ndarray`中）时，将触发全局解释器锁，从而使所有GPU阻塞。最好是为GPU内部的日志分配内存，并且只移动较大的日志。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ac0066-2470-43ad-ad5a-b4990b6ee71c",
   "metadata": {},
   "source": [
    "### 练习\n",
    "1. 尝试一个计算量更大的任务，比如大矩阵的乘法，看看CPU和GPU之间的速度差异。再试一个计算量很小的任务呢？\n",
    "- GPU很快啊\n",
    "    - `round(..., n)`：对计算结果保留两位小数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a41e7546-980d-4a9a-ae84-e1c6b83b2348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "larger cup time cost:13253ms\n",
      "larger gpu time cost:60ms\n",
      "smaller cup time cost:15225ms\n",
      "smaller gpu time cost:0ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "# 计算量较大的任务\n",
    "X = torch.rand((10000, 10000))\n",
    "Y = X.cuda(0)\n",
    "time_start = time.time()\n",
    "Z = torch.mm(X, X)\n",
    "time_end = time.time()\n",
    "print(f'larger cup time cost:{round((time_end - time_start) * 1000)}ms') \n",
    "\n",
    "time_start = time.time()\n",
    "Z = torch.mm(Y, Y)\n",
    "time_end = time.time()\n",
    "print(f'larger gpu time cost:{round((time_end - time_start) * 1000)}ms') \n",
    "\n",
    "# 计算很小的任务\n",
    "X = torch.rand((100, 100))\n",
    "Y = X.cuda()\n",
    "Z = torch.mm(X, X)\n",
    "time_end = time.time()\n",
    "print(f'smaller cup time cost:{round((time_end - time_start) * 1000)}ms') \n",
    "\n",
    "time_start = time.time()\n",
    "Z = torch.mm(Y, Y)\n",
    "time_end = time.time()\n",
    "print(f'smaller gpu time cost:{round((time_end - time_start) * 1000)}ms') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8800fc78-0570-4c68-ad16-61fa2b12a6c1",
   "metadata": {},
   "source": [
    "2. 我们应该如何在GPU上读写模型参数？\n",
    "- 使用`net.to(device)`将模型迁移到GPU上，然后在按照之前的方法读写参数\n",
    "- `map_location=device`的作用：指定在加载模型时，**将模型加载到指定的设备上**`torch.load('', map_location= )`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9a10f83-71b9-4d13-a6ac-6b9241bbe842",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden.weight',\n",
       "              tensor([[ 0.0689, -0.0808, -0.1696,  ..., -0.0320,  0.0182,  0.1520],\n",
       "                      [ 0.1008,  0.0257,  0.0150,  ...,  0.1943, -0.1240,  0.1649],\n",
       "                      [ 0.1503,  0.1013, -0.1000,  ..., -0.2010,  0.2142, -0.0440],\n",
       "                      ...,\n",
       "                      [-0.0238,  0.0241, -0.2109,  ..., -0.0222, -0.1948, -0.1119],\n",
       "                      [ 0.1238,  0.1051, -0.0006,  ..., -0.0684, -0.1344, -0.0890],\n",
       "                      [-0.1737,  0.1602, -0.0364,  ..., -0.1696, -0.2107, -0.1506]],\n",
       "                     device='cuda:0')),\n",
       "             ('hidden.bias',\n",
       "              tensor([ 2.0553e-01, -3.9608e-02, -2.0917e-02, -2.5621e-02,  1.7343e-01,\n",
       "                       5.3473e-02,  9.8627e-02,  6.6556e-02,  1.1647e-01,  2.0590e-01,\n",
       "                       1.7302e-01, -1.8309e-01, -1.3410e-01, -1.4530e-01,  1.2473e-02,\n",
       "                       1.3898e-02, -2.1442e-02,  1.7967e-02,  1.3954e-01,  1.8899e-01,\n",
       "                       1.2473e-01, -1.0171e-01,  2.1309e-01,  1.0177e-01,  9.2268e-02,\n",
       "                      -1.5100e-01, -1.2907e-02, -3.3098e-03,  4.1438e-02, -1.9560e-01,\n",
       "                       1.4138e-03,  2.0210e-01,  9.0276e-02, -8.8464e-02,  5.0213e-02,\n",
       "                      -9.4418e-02,  7.9991e-02, -1.4910e-01,  5.0413e-02,  6.2756e-02,\n",
       "                      -1.6215e-01,  8.9280e-02, -1.0272e-02, -1.4752e-01,  1.0462e-01,\n",
       "                      -1.0884e-01,  2.0392e-01,  2.1922e-01, -1.6176e-01,  1.2722e-01,\n",
       "                      -2.0885e-01,  5.5939e-02,  7.6691e-02,  1.9532e-01,  1.4246e-01,\n",
       "                      -1.8839e-01,  2.5799e-02, -7.1827e-02,  2.1940e-01, -5.2353e-02,\n",
       "                       1.7311e-02,  6.0151e-02,  5.7226e-02,  9.8131e-02,  1.6640e-01,\n",
       "                       9.5520e-03, -7.3090e-02, -2.1512e-01, -6.4683e-02, -7.9721e-02,\n",
       "                       1.9209e-01, -6.3274e-02, -1.0910e-01,  1.6092e-01, -8.1724e-02,\n",
       "                       9.8817e-02,  1.2010e-01, -1.6852e-01,  1.7562e-01,  7.0426e-02,\n",
       "                       1.2267e-01,  4.2921e-02, -6.9602e-02,  2.1233e-01, -1.2306e-01,\n",
       "                       5.9802e-03,  1.9345e-04,  1.7882e-01, -2.3920e-02,  2.2347e-01,\n",
       "                       1.5533e-01, -2.1725e-01,  2.2288e-01,  2.4974e-02, -1.7767e-01,\n",
       "                      -1.9241e-02, -5.7537e-02, -3.9175e-02, -3.8009e-02,  4.8106e-03,\n",
       "                       3.7340e-03,  1.7067e-01, -1.7966e-01,  1.2038e-01,  1.8911e-02,\n",
       "                       2.0217e-01,  1.4702e-01, -1.2456e-01,  1.0436e-01,  5.3078e-02,\n",
       "                       3.4367e-02, -2.1040e-02,  1.8770e-01, -1.2829e-01, -2.1434e-01,\n",
       "                      -1.5189e-01, -1.1228e-01, -2.1209e-01,  1.2207e-01,  2.3698e-02,\n",
       "                       1.2706e-01, -5.1436e-02, -9.4232e-02, -1.8374e-01, -1.6363e-01,\n",
       "                       3.4022e-02,  1.3683e-01,  1.0170e-01,  8.5170e-02,  1.9596e-01,\n",
       "                       4.9797e-02, -4.1055e-03, -1.6555e-01, -1.6000e-01,  1.5083e-01,\n",
       "                       2.1104e-02,  6.7045e-02,  6.5994e-02,  6.6458e-02,  8.1444e-02,\n",
       "                      -1.3579e-01, -2.0722e-01, -6.9862e-02, -7.3066e-02, -1.9824e-01,\n",
       "                      -4.9308e-02,  1.0663e-01,  9.8128e-02, -1.4595e-01, -4.6288e-02,\n",
       "                       1.0646e-01, -2.0773e-01, -8.3108e-02, -2.0081e-01,  1.9991e-01,\n",
       "                      -1.7160e-01, -2.0129e-01,  6.4432e-02, -9.3813e-02, -2.6621e-02,\n",
       "                      -1.5755e-01,  1.4483e-02,  4.7851e-02, -9.5222e-02,  4.9652e-04,\n",
       "                      -2.0374e-01,  3.0434e-02, -3.3318e-03, -2.0940e-01,  6.4320e-02,\n",
       "                       2.0878e-01,  1.4404e-01,  1.2092e-02, -1.6604e-03, -8.7409e-02,\n",
       "                       4.7217e-02,  1.5114e-01,  4.7263e-02,  1.8668e-01, -1.8655e-01,\n",
       "                      -1.4778e-01,  1.9264e-01,  8.0063e-02, -8.7559e-04,  5.1785e-02,\n",
       "                       2.1993e-01, -5.4134e-02, -5.8759e-03, -8.2732e-02,  3.5537e-03,\n",
       "                       1.8977e-01,  2.1530e-01, -1.6835e-01,  2.3957e-02,  5.1134e-02,\n",
       "                      -7.0933e-02, -1.0340e-01,  1.1314e-01, -8.3000e-02,  2.1264e-01,\n",
       "                      -1.5621e-01,  1.4181e-01, -2.0568e-01,  3.0572e-02,  1.7174e-01,\n",
       "                       1.8196e-01,  1.1807e-01, -3.2283e-02, -1.0572e-02,  2.5430e-02,\n",
       "                      -9.0472e-03, -1.0632e-01,  1.2883e-01, -1.8227e-01,  9.3361e-02,\n",
       "                       1.1620e-01,  2.0622e-01,  5.3704e-02,  1.0976e-01,  1.6177e-01,\n",
       "                      -8.9360e-02, -6.0314e-02, -9.2238e-04, -1.6382e-01,  2.2331e-01,\n",
       "                       2.2106e-01, -8.2094e-03,  1.8761e-01,  7.6272e-02, -4.0987e-02,\n",
       "                      -1.3526e-01, -2.2222e-01,  2.1222e-01, -1.9251e-01, -1.2593e-01,\n",
       "                      -9.1986e-02, -1.2780e-01,  1.1888e-01,  3.6225e-02, -5.3055e-02,\n",
       "                      -1.6279e-01,  9.8466e-02,  1.7490e-01,  7.0781e-02,  1.2582e-01,\n",
       "                      -1.5571e-01, -5.0380e-02, -1.3791e-01, -4.8343e-02,  4.6669e-04,\n",
       "                      -5.3012e-02, -7.7014e-02,  1.7300e-01, -1.9373e-01, -2.0124e-01,\n",
       "                      -3.0542e-03], device='cuda:0')),\n",
       "             ('output.weight',\n",
       "              tensor([[ 0.0411, -0.0467,  0.0446,  ...,  0.0506,  0.0494,  0.0582],\n",
       "                      [-0.0022, -0.0254,  0.0408,  ..., -0.0374, -0.0513,  0.0059],\n",
       "                      [ 0.0489,  0.0290, -0.0616,  ...,  0.0325,  0.0531, -0.0474],\n",
       "                      ...,\n",
       "                      [ 0.0395,  0.0487,  0.0484,  ...,  0.0090,  0.0407, -0.0229],\n",
       "                      [-0.0351, -0.0066, -0.0319,  ...,  0.0473, -0.0588, -0.0600],\n",
       "                      [-0.0089, -0.0414, -0.0223,  ...,  0.0595,  0.0263,  0.0504]],\n",
       "                     device='cuda:0')),\n",
       "             ('output.bias',\n",
       "              tensor([ 0.0568,  0.0132,  0.0255,  0.0408,  0.0242,  0.0124, -0.0256, -0.0471,\n",
       "                       0.0204, -0.0395], device='cuda:0'))])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.output(F.relu(self.hidden(X)))\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "net = MLP()\n",
    "net.to(device=device)\n",
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "777ffebf-fccd-4d66-9404-6159b02eed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(5, 20).to(device)\n",
    "output = net(X)\n",
    "\n",
    "torch.save(net.state_dict(), 'net_params.pth')\n",
    "net.load_state_dict(torch.load('net_params.pth', map_location=device))\n",
    "\n",
    "# 从GPU读取到CPU\n",
    "cpu_params = {name: param.cpu() for name, param in net.named_parameters()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b92c4e-ec86-4754-a87b-2f1ac6fc3634",
   "metadata": {},
   "source": [
    "3. 测量计算1000个$100 \\times 100$矩阵的矩阵乘法所需的时间，并记录输出矩阵的Frobenius范数，一次记录一个结果，而不是在GPU上保存日志并仅传输最终结果。（本质是做一个比较）\n",
    "- 实验1：仅记录1000次$100\\times100$次矩阵相乘做用的时间，不需要打印Frobenius范数\n",
    "- 实验2：记录1000次$100\\times100$次矩阵相乘，并每次计算一次就打印Frobenius范数的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "881af83b-519e-4d62-a308-8c00e472870d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.04256129264831543\n",
      "tensor(2526.0168, device='cuda:0')\n",
      "tensor(2495.0190, device='cuda:0')\n",
      "tensor(2502.0378, device='cuda:0')\n",
      "tensor(2500.8809, device='cuda:0')\n",
      "tensor(2518.0093, device='cuda:0')\n",
      "tensor(2534.0884, device='cuda:0')\n",
      "tensor(2496.5613, device='cuda:0')\n",
      "tensor(2511.5728, device='cuda:0')\n",
      "tensor(2523.3743, device='cuda:0')\n",
      "tensor(2495.8501, device='cuda:0')\n",
      "tensor(2465.7292, device='cuda:0')\n",
      "tensor(2521.1113, device='cuda:0')\n",
      "tensor(2536.7524, device='cuda:0')\n",
      "tensor(2475.3669, device='cuda:0')\n",
      "tensor(2524.8977, device='cuda:0')\n",
      "tensor(2474.9875, device='cuda:0')\n",
      "tensor(2543.5774, device='cuda:0')\n",
      "tensor(2518.3130, device='cuda:0')\n",
      "tensor(2541.7900, device='cuda:0')\n",
      "tensor(2565.8616, device='cuda:0')\n",
      "tensor(2510.6245, device='cuda:0')\n",
      "tensor(2472.4509, device='cuda:0')\n",
      "tensor(2496.3140, device='cuda:0')\n",
      "tensor(2539.9141, device='cuda:0')\n",
      "tensor(2485.4585, device='cuda:0')\n",
      "tensor(2495.1040, device='cuda:0')\n",
      "tensor(2516.9851, device='cuda:0')\n",
      "tensor(2536.8887, device='cuda:0')\n",
      "tensor(2488.5520, device='cuda:0')\n",
      "tensor(2475.8201, device='cuda:0')\n",
      "tensor(2546.5127, device='cuda:0')\n",
      "tensor(2503.2109, device='cuda:0')\n",
      "tensor(2478.5422, device='cuda:0')\n",
      "tensor(2520.9019, device='cuda:0')\n",
      "tensor(2548.6270, device='cuda:0')\n",
      "tensor(2537.7322, device='cuda:0')\n",
      "tensor(2467.7861, device='cuda:0')\n",
      "tensor(2450.3208, device='cuda:0')\n",
      "tensor(2468.5371, device='cuda:0')\n",
      "tensor(2544.3586, device='cuda:0')\n",
      "tensor(2525.1509, device='cuda:0')\n",
      "tensor(2514.2397, device='cuda:0')\n",
      "tensor(2484.1760, device='cuda:0')\n",
      "tensor(2488.3499, device='cuda:0')\n",
      "tensor(2496.4324, device='cuda:0')\n",
      "tensor(2532.9343, device='cuda:0')\n",
      "tensor(2515.6157, device='cuda:0')\n",
      "tensor(2500.1006, device='cuda:0')\n",
      "tensor(2497.5605, device='cuda:0')\n",
      "tensor(2489.9631, device='cuda:0')\n",
      "tensor(2515.8679, device='cuda:0')\n",
      "tensor(2484.0513, device='cuda:0')\n",
      "tensor(2542.8809, device='cuda:0')\n",
      "tensor(2558.9165, device='cuda:0')\n",
      "tensor(2503.0144, device='cuda:0')\n",
      "tensor(2454.9229, device='cuda:0')\n",
      "tensor(2551.8555, device='cuda:0')\n",
      "tensor(2490.1577, device='cuda:0')\n",
      "tensor(2480.6204, device='cuda:0')\n",
      "tensor(2493.4785, device='cuda:0')\n",
      "tensor(2490.8066, device='cuda:0')\n",
      "tensor(2552.1047, device='cuda:0')\n",
      "tensor(2527.0483, device='cuda:0')\n",
      "tensor(2483.5623, device='cuda:0')\n",
      "tensor(2527.8506, device='cuda:0')\n",
      "tensor(2538.7053, device='cuda:0')\n",
      "tensor(2496.1064, device='cuda:0')\n",
      "tensor(2501.6992, device='cuda:0')\n",
      "tensor(2496.5288, device='cuda:0')\n",
      "tensor(2538.7061, device='cuda:0')\n",
      "tensor(2520.7837, device='cuda:0')\n",
      "tensor(2539.4448, device='cuda:0')\n",
      "tensor(2523.7446, device='cuda:0')\n",
      "tensor(2491.6375, device='cuda:0')\n",
      "tensor(2487.1948, device='cuda:0')\n",
      "tensor(2509.1350, device='cuda:0')\n",
      "tensor(2518.7732, device='cuda:0')\n",
      "tensor(2475.5266, device='cuda:0')\n",
      "tensor(2561.1145, device='cuda:0')\n",
      "tensor(2559.7856, device='cuda:0')\n",
      "tensor(2489.8235, device='cuda:0')\n",
      "tensor(2488.2803, device='cuda:0')\n",
      "tensor(2517.9927, device='cuda:0')\n",
      "tensor(2449.6099, device='cuda:0')\n",
      "tensor(2508.1509, device='cuda:0')\n",
      "tensor(2575.1252, device='cuda:0')\n",
      "tensor(2507.4954, device='cuda:0')\n",
      "tensor(2505.6172, device='cuda:0')\n",
      "tensor(2500.5559, device='cuda:0')\n",
      "tensor(2516.6992, device='cuda:0')\n",
      "tensor(2524.3320, device='cuda:0')\n",
      "tensor(2518.0959, device='cuda:0')\n",
      "tensor(2540.2476, device='cuda:0')\n",
      "tensor(2506.2300, device='cuda:0')\n",
      "tensor(2496.2371, device='cuda:0')\n",
      "tensor(2489.0090, device='cuda:0')\n",
      "tensor(2498.7976, device='cuda:0')\n",
      "tensor(2481.9678, device='cuda:0')\n",
      "tensor(2541.5247, device='cuda:0')\n",
      "tensor(2528.1453, device='cuda:0')\n",
      "tensor(2438.8047, device='cuda:0')\n",
      "tensor(2476.3342, device='cuda:0')\n",
      "tensor(2487.7153, device='cuda:0')\n",
      "tensor(2508.0598, device='cuda:0')\n",
      "tensor(2517.9387, device='cuda:0')\n",
      "tensor(2508.8701, device='cuda:0')\n",
      "tensor(2478.5276, device='cuda:0')\n",
      "tensor(2505.0212, device='cuda:0')\n",
      "tensor(2486.6431, device='cuda:0')\n",
      "tensor(2481.5781, device='cuda:0')\n",
      "tensor(2489.8608, device='cuda:0')\n",
      "tensor(2551.4741, device='cuda:0')\n",
      "tensor(2543.7673, device='cuda:0')\n",
      "tensor(2450.8530, device='cuda:0')\n",
      "tensor(2524.5930, device='cuda:0')\n",
      "tensor(2523.6951, device='cuda:0')\n",
      "tensor(2466.5840, device='cuda:0')\n",
      "tensor(2513.5002, device='cuda:0')\n",
      "tensor(2495.3142, device='cuda:0')\n",
      "tensor(2574.9829, device='cuda:0')\n",
      "tensor(2483.1987, device='cuda:0')\n",
      "tensor(2504.4834, device='cuda:0')\n",
      "tensor(2488.3379, device='cuda:0')\n",
      "tensor(2483.3257, device='cuda:0')\n",
      "tensor(2497.3767, device='cuda:0')\n",
      "tensor(2510.4412, device='cuda:0')\n",
      "tensor(2478.5403, device='cuda:0')\n",
      "tensor(2554.8464, device='cuda:0')\n",
      "tensor(2503.9910, device='cuda:0')\n",
      "tensor(2479.4177, device='cuda:0')\n",
      "tensor(2455.6414, device='cuda:0')\n",
      "tensor(2528.9241, device='cuda:0')\n",
      "tensor(2509.2744, device='cuda:0')\n",
      "tensor(2483.0762, device='cuda:0')\n",
      "tensor(2486.5647, device='cuda:0')\n",
      "tensor(2480.7749, device='cuda:0')\n",
      "tensor(2515.0122, device='cuda:0')\n",
      "tensor(2469.5581, device='cuda:0')\n",
      "tensor(2467.3162, device='cuda:0')\n",
      "tensor(2516.3010, device='cuda:0')\n",
      "tensor(2554.6008, device='cuda:0')\n",
      "tensor(2553.6248, device='cuda:0')\n",
      "tensor(2446.4541, device='cuda:0')\n",
      "tensor(2543.4624, device='cuda:0')\n",
      "tensor(2488.4316, device='cuda:0')\n",
      "tensor(2490.0940, device='cuda:0')\n",
      "tensor(2514.8914, device='cuda:0')\n",
      "tensor(2460.4585, device='cuda:0')\n",
      "tensor(2540.9905, device='cuda:0')\n",
      "tensor(2497.9531, device='cuda:0')\n",
      "tensor(2538.6221, device='cuda:0')\n",
      "tensor(2464.5964, device='cuda:0')\n",
      "tensor(2514.8940, device='cuda:0')\n",
      "tensor(2505.0918, device='cuda:0')\n",
      "tensor(2521.4561, device='cuda:0')\n",
      "tensor(2516.8081, device='cuda:0')\n",
      "tensor(2518.5132, device='cuda:0')\n",
      "tensor(2546.3472, device='cuda:0')\n",
      "tensor(2553.2454, device='cuda:0')\n",
      "tensor(2516.0090, device='cuda:0')\n",
      "tensor(2560.3347, device='cuda:0')\n",
      "tensor(2474.0730, device='cuda:0')\n",
      "tensor(2553.2644, device='cuda:0')\n",
      "tensor(2494.7122, device='cuda:0')\n",
      "tensor(2498.0952, device='cuda:0')\n",
      "tensor(2570.1567, device='cuda:0')\n",
      "tensor(2465.4297, device='cuda:0')\n",
      "tensor(2514.6702, device='cuda:0')\n",
      "tensor(2465.9910, device='cuda:0')\n",
      "tensor(2472.7883, device='cuda:0')\n",
      "tensor(2534.0703, device='cuda:0')\n",
      "tensor(2541.6389, device='cuda:0')\n",
      "tensor(2509.6443, device='cuda:0')\n",
      "tensor(2509.7190, device='cuda:0')\n",
      "tensor(2548.8948, device='cuda:0')\n",
      "tensor(2530.1848, device='cuda:0')\n",
      "tensor(2499.6309, device='cuda:0')\n",
      "tensor(2490.7014, device='cuda:0')\n",
      "tensor(2515.1111, device='cuda:0')\n",
      "tensor(2498.9229, device='cuda:0')\n",
      "tensor(2481.2498, device='cuda:0')\n",
      "tensor(2498.0188, device='cuda:0')\n",
      "tensor(2491.5212, device='cuda:0')\n",
      "tensor(2505.9111, device='cuda:0')\n",
      "tensor(2499.5042, device='cuda:0')\n",
      "tensor(2460.8616, device='cuda:0')\n",
      "tensor(2518.3984, device='cuda:0')\n",
      "tensor(2546.3533, device='cuda:0')\n",
      "tensor(2468.7207, device='cuda:0')\n",
      "tensor(2509.8552, device='cuda:0')\n",
      "tensor(2554.4636, device='cuda:0')\n",
      "tensor(2470.6416, device='cuda:0')\n",
      "tensor(2477.6885, device='cuda:0')\n",
      "tensor(2453.8406, device='cuda:0')\n",
      "tensor(2469.8687, device='cuda:0')\n",
      "tensor(2576.7866, device='cuda:0')\n",
      "tensor(2514.1787, device='cuda:0')\n",
      "tensor(2547.1201, device='cuda:0')\n",
      "tensor(2480.4741, device='cuda:0')\n",
      "tensor(2536.9697, device='cuda:0')\n",
      "tensor(2501.1492, device='cuda:0')\n",
      "tensor(2490.5833, device='cuda:0')\n",
      "tensor(2450.3115, device='cuda:0')\n",
      "tensor(2522.4543, device='cuda:0')\n",
      "tensor(2529.6150, device='cuda:0')\n",
      "tensor(2526.2234, device='cuda:0')\n",
      "tensor(2496.2241, device='cuda:0')\n",
      "tensor(2489.8738, device='cuda:0')\n",
      "tensor(2583.9094, device='cuda:0')\n",
      "tensor(2535.2781, device='cuda:0')\n",
      "tensor(2526.0991, device='cuda:0')\n",
      "tensor(2538.5222, device='cuda:0')\n",
      "tensor(2492.9380, device='cuda:0')\n",
      "tensor(2511.7856, device='cuda:0')\n",
      "tensor(2484.7773, device='cuda:0')\n",
      "tensor(2442.1855, device='cuda:0')\n",
      "tensor(2492.5869, device='cuda:0')\n",
      "tensor(2492.3103, device='cuda:0')\n",
      "tensor(2507.0115, device='cuda:0')\n",
      "tensor(2494.1963, device='cuda:0')\n",
      "tensor(2481.9331, device='cuda:0')\n",
      "tensor(2563.5032, device='cuda:0')\n",
      "tensor(2510.2949, device='cuda:0')\n",
      "tensor(2531.9160, device='cuda:0')\n",
      "tensor(2518.7537, device='cuda:0')\n",
      "tensor(2537.7444, device='cuda:0')\n",
      "tensor(2512.6338, device='cuda:0')\n",
      "tensor(2485.6868, device='cuda:0')\n",
      "tensor(2514.8613, device='cuda:0')\n",
      "tensor(2514.1218, device='cuda:0')\n",
      "tensor(2513.6926, device='cuda:0')\n",
      "tensor(2522.6646, device='cuda:0')\n",
      "tensor(2475.3069, device='cuda:0')\n",
      "tensor(2543.3811, device='cuda:0')\n",
      "tensor(2481.2534, device='cuda:0')\n",
      "tensor(2530.0918, device='cuda:0')\n",
      "tensor(2529.2542, device='cuda:0')\n",
      "tensor(2569.1914, device='cuda:0')\n",
      "tensor(2531.4487, device='cuda:0')\n",
      "tensor(2537.9736, device='cuda:0')\n",
      "tensor(2520.6353, device='cuda:0')\n",
      "tensor(2516.1316, device='cuda:0')\n",
      "tensor(2499.3977, device='cuda:0')\n",
      "tensor(2551.6499, device='cuda:0')\n",
      "tensor(2532.6682, device='cuda:0')\n",
      "tensor(2503.9490, device='cuda:0')\n",
      "tensor(2491.8914, device='cuda:0')\n",
      "tensor(2526.1838, device='cuda:0')\n",
      "tensor(2496.3621, device='cuda:0')\n",
      "tensor(2538.9937, device='cuda:0')\n",
      "tensor(2523.8840, device='cuda:0')\n",
      "tensor(2438.1699, device='cuda:0')\n",
      "tensor(2568.7756, device='cuda:0')\n",
      "tensor(2510.6365, device='cuda:0')\n",
      "tensor(2489.6211, device='cuda:0')\n",
      "tensor(2529.7634, device='cuda:0')\n",
      "tensor(2522.6270, device='cuda:0')\n",
      "tensor(2506.6550, device='cuda:0')\n",
      "tensor(2548.7021, device='cuda:0')\n",
      "tensor(2518.4604, device='cuda:0')\n",
      "tensor(2463.3728, device='cuda:0')\n",
      "tensor(2531.1941, device='cuda:0')\n",
      "tensor(2499.8633, device='cuda:0')\n",
      "tensor(2478.9373, device='cuda:0')\n",
      "tensor(2463.8792, device='cuda:0')\n",
      "tensor(2507.1011, device='cuda:0')\n",
      "tensor(2515.1970, device='cuda:0')\n",
      "tensor(2499.2659, device='cuda:0')\n",
      "tensor(2491.7759, device='cuda:0')\n",
      "tensor(2472.5596, device='cuda:0')\n",
      "tensor(2525.5557, device='cuda:0')\n",
      "tensor(2555.8169, device='cuda:0')\n",
      "tensor(2536.4700, device='cuda:0')\n",
      "tensor(2499.1101, device='cuda:0')\n",
      "tensor(2510.8843, device='cuda:0')\n",
      "tensor(2478.3257, device='cuda:0')\n",
      "tensor(2486.5452, device='cuda:0')\n",
      "tensor(2474.1992, device='cuda:0')\n",
      "tensor(2540.1055, device='cuda:0')\n",
      "tensor(2515.8521, device='cuda:0')\n",
      "tensor(2475.6584, device='cuda:0')\n",
      "tensor(2489.8289, device='cuda:0')\n",
      "tensor(2514.2441, device='cuda:0')\n",
      "tensor(2524.7026, device='cuda:0')\n",
      "tensor(2456.1655, device='cuda:0')\n",
      "tensor(2596.1423, device='cuda:0')\n",
      "tensor(2519.1428, device='cuda:0')\n",
      "tensor(2525.2122, device='cuda:0')\n",
      "tensor(2495.7373, device='cuda:0')\n",
      "tensor(2563.0508, device='cuda:0')\n",
      "tensor(2535.6196, device='cuda:0')\n",
      "tensor(2514.6316, device='cuda:0')\n",
      "tensor(2463.6721, device='cuda:0')\n",
      "tensor(2530.8015, device='cuda:0')\n",
      "tensor(2501.3289, device='cuda:0')\n",
      "tensor(2490.5708, device='cuda:0')\n",
      "tensor(2507.5762, device='cuda:0')\n",
      "tensor(2511.6670, device='cuda:0')\n",
      "tensor(2478.2473, device='cuda:0')\n",
      "tensor(2515.2908, device='cuda:0')\n",
      "tensor(2512.1836, device='cuda:0')\n",
      "tensor(2559.1082, device='cuda:0')\n",
      "tensor(2510.1001, device='cuda:0')\n",
      "tensor(2478.9797, device='cuda:0')\n",
      "tensor(2506.6479, device='cuda:0')\n",
      "tensor(2523.3325, device='cuda:0')\n",
      "tensor(2523.8174, device='cuda:0')\n",
      "tensor(2487.6628, device='cuda:0')\n",
      "tensor(2524.0312, device='cuda:0')\n",
      "tensor(2517.0986, device='cuda:0')\n",
      "tensor(2516.1780, device='cuda:0')\n",
      "tensor(2468.8823, device='cuda:0')\n",
      "tensor(2443.9392, device='cuda:0')\n",
      "tensor(2502.5679, device='cuda:0')\n",
      "tensor(2503.4092, device='cuda:0')\n",
      "tensor(2505.8550, device='cuda:0')\n",
      "tensor(2540.0908, device='cuda:0')\n",
      "tensor(2534.6936, device='cuda:0')\n",
      "tensor(2502.7065, device='cuda:0')\n",
      "tensor(2531.8779, device='cuda:0')\n",
      "tensor(2572.5354, device='cuda:0')\n",
      "tensor(2537.9985, device='cuda:0')\n",
      "tensor(2493.5830, device='cuda:0')\n",
      "tensor(2492.8545, device='cuda:0')\n",
      "tensor(2527.1611, device='cuda:0')\n",
      "tensor(2504.5486, device='cuda:0')\n",
      "tensor(2460.4250, device='cuda:0')\n",
      "tensor(2505.6882, device='cuda:0')\n",
      "tensor(2498.0081, device='cuda:0')\n",
      "tensor(2533.9358, device='cuda:0')\n",
      "tensor(2530.7737, device='cuda:0')\n",
      "tensor(2450.3594, device='cuda:0')\n",
      "tensor(2488.3508, device='cuda:0')\n",
      "tensor(2480.0659, device='cuda:0')\n",
      "tensor(2509.4937, device='cuda:0')\n",
      "tensor(2537.8508, device='cuda:0')\n",
      "tensor(2534.1160, device='cuda:0')\n",
      "tensor(2555.7070, device='cuda:0')\n",
      "tensor(2459.6296, device='cuda:0')\n",
      "tensor(2484.3181, device='cuda:0')\n",
      "tensor(2545.4819, device='cuda:0')\n",
      "tensor(2560.3408, device='cuda:0')\n",
      "tensor(2484.8840, device='cuda:0')\n",
      "tensor(2566.7444, device='cuda:0')\n",
      "tensor(2549.6790, device='cuda:0')\n",
      "tensor(2540.8301, device='cuda:0')\n",
      "tensor(2507.6875, device='cuda:0')\n",
      "tensor(2534.5178, device='cuda:0')\n",
      "tensor(2491.9146, device='cuda:0')\n",
      "tensor(2480.2053, device='cuda:0')\n",
      "tensor(2514.4480, device='cuda:0')\n",
      "tensor(2519.5242, device='cuda:0')\n",
      "tensor(2489.4138, device='cuda:0')\n",
      "tensor(2486.2461, device='cuda:0')\n",
      "tensor(2530.6753, device='cuda:0')\n",
      "tensor(2464.1682, device='cuda:0')\n",
      "tensor(2530.8599, device='cuda:0')\n",
      "tensor(2483.3923, device='cuda:0')\n",
      "tensor(2518.1868, device='cuda:0')\n",
      "tensor(2498.9480, device='cuda:0')\n",
      "tensor(2531.7571, device='cuda:0')\n",
      "tensor(2520.3167, device='cuda:0')\n",
      "tensor(2487.6143, device='cuda:0')\n",
      "tensor(2485.2498, device='cuda:0')\n",
      "tensor(2545.1025, device='cuda:0')\n",
      "tensor(2511.3635, device='cuda:0')\n",
      "tensor(2477.3303, device='cuda:0')\n",
      "tensor(2516.2842, device='cuda:0')\n",
      "tensor(2526.2512, device='cuda:0')\n",
      "tensor(2506.4966, device='cuda:0')\n",
      "tensor(2517.8284, device='cuda:0')\n",
      "tensor(2527.8772, device='cuda:0')\n",
      "tensor(2518.8171, device='cuda:0')\n",
      "tensor(2508.2368, device='cuda:0')\n",
      "tensor(2490.6975, device='cuda:0')\n",
      "tensor(2480.8894, device='cuda:0')\n",
      "tensor(2534.9648, device='cuda:0')\n",
      "tensor(2544.2339, device='cuda:0')\n",
      "tensor(2485.5852, device='cuda:0')\n",
      "tensor(2476.0210, device='cuda:0')\n",
      "tensor(2512.3323, device='cuda:0')\n",
      "tensor(2508.4382, device='cuda:0')\n",
      "tensor(2493.0706, device='cuda:0')\n",
      "tensor(2449.2905, device='cuda:0')\n",
      "tensor(2488.4568, device='cuda:0')\n",
      "tensor(2537.2949, device='cuda:0')\n",
      "tensor(2538.6614, device='cuda:0')\n",
      "tensor(2535.0969, device='cuda:0')\n",
      "tensor(2533.1746, device='cuda:0')\n",
      "tensor(2549.7559, device='cuda:0')\n",
      "tensor(2504.0522, device='cuda:0')\n",
      "tensor(2537.4062, device='cuda:0')\n",
      "tensor(2501.5825, device='cuda:0')\n",
      "tensor(2550.6616, device='cuda:0')\n",
      "tensor(2531.3901, device='cuda:0')\n",
      "tensor(2513.2566, device='cuda:0')\n",
      "tensor(2441.4565, device='cuda:0')\n",
      "tensor(2506.2927, device='cuda:0')\n",
      "tensor(2542.4026, device='cuda:0')\n",
      "tensor(2464.4192, device='cuda:0')\n",
      "tensor(2502.6399, device='cuda:0')\n",
      "tensor(2506.2327, device='cuda:0')\n",
      "tensor(2502.9536, device='cuda:0')\n",
      "tensor(2468.6997, device='cuda:0')\n",
      "tensor(2475.1042, device='cuda:0')\n",
      "tensor(2528.9580, device='cuda:0')\n",
      "tensor(2527.5308, device='cuda:0')\n",
      "tensor(2470.1250, device='cuda:0')\n",
      "tensor(2459.1997, device='cuda:0')\n",
      "tensor(2487.8687, device='cuda:0')\n",
      "tensor(2558.7043, device='cuda:0')\n",
      "tensor(2536.2830, device='cuda:0')\n",
      "tensor(2475.7080, device='cuda:0')\n",
      "tensor(2523.8250, device='cuda:0')\n",
      "tensor(2515.5723, device='cuda:0')\n",
      "tensor(2530.1140, device='cuda:0')\n",
      "tensor(2503.5098, device='cuda:0')\n",
      "tensor(2513.7227, device='cuda:0')\n",
      "tensor(2492.1035, device='cuda:0')\n",
      "tensor(2475.1855, device='cuda:0')\n",
      "tensor(2549.4102, device='cuda:0')\n",
      "tensor(2487.2136, device='cuda:0')\n",
      "tensor(2491.6121, device='cuda:0')\n",
      "tensor(2549.5662, device='cuda:0')\n",
      "tensor(2472.8511, device='cuda:0')\n",
      "tensor(2461.8701, device='cuda:0')\n",
      "tensor(2528.6064, device='cuda:0')\n",
      "tensor(2532.8025, device='cuda:0')\n",
      "tensor(2484.9912, device='cuda:0')\n",
      "tensor(2533.1467, device='cuda:0')\n",
      "tensor(2553.1243, device='cuda:0')\n",
      "tensor(2493.5137, device='cuda:0')\n",
      "tensor(2488.0024, device='cuda:0')\n",
      "tensor(2592.7927, device='cuda:0')\n",
      "tensor(2516.1084, device='cuda:0')\n",
      "tensor(2494.8257, device='cuda:0')\n",
      "tensor(2506.7712, device='cuda:0')\n",
      "tensor(2532.3479, device='cuda:0')\n",
      "tensor(2470.6714, device='cuda:0')\n",
      "tensor(2499.8181, device='cuda:0')\n",
      "tensor(2496.7271, device='cuda:0')\n",
      "tensor(2496.8635, device='cuda:0')\n",
      "tensor(2461.0854, device='cuda:0')\n",
      "tensor(2489.5701, device='cuda:0')\n",
      "tensor(2538.6057, device='cuda:0')\n",
      "tensor(2530.2246, device='cuda:0')\n",
      "tensor(2499.9597, device='cuda:0')\n",
      "tensor(2512.7070, device='cuda:0')\n",
      "tensor(2486.5100, device='cuda:0')\n",
      "tensor(2538.1912, device='cuda:0')\n",
      "tensor(2489.0381, device='cuda:0')\n",
      "tensor(2512.6333, device='cuda:0')\n",
      "tensor(2542.6428, device='cuda:0')\n",
      "tensor(2499.7197, device='cuda:0')\n",
      "tensor(2527.1624, device='cuda:0')\n",
      "tensor(2498.8530, device='cuda:0')\n",
      "tensor(2550.9812, device='cuda:0')\n",
      "tensor(2505.8892, device='cuda:0')\n",
      "tensor(2486.7676, device='cuda:0')\n",
      "tensor(2528.5308, device='cuda:0')\n",
      "tensor(2502.9431, device='cuda:0')\n",
      "tensor(2540.4231, device='cuda:0')\n",
      "tensor(2538.8374, device='cuda:0')\n",
      "tensor(2441.4343, device='cuda:0')\n",
      "tensor(2540.9009, device='cuda:0')\n",
      "tensor(2487.8787, device='cuda:0')\n",
      "tensor(2507.2168, device='cuda:0')\n",
      "tensor(2525.7502, device='cuda:0')\n",
      "tensor(2557.1301, device='cuda:0')\n",
      "tensor(2506.1191, device='cuda:0')\n",
      "tensor(2496.2590, device='cuda:0')\n",
      "tensor(2519.8262, device='cuda:0')\n",
      "tensor(2502.5859, device='cuda:0')\n",
      "tensor(2559.3223, device='cuda:0')\n",
      "tensor(2531.9353, device='cuda:0')\n",
      "tensor(2519.7112, device='cuda:0')\n",
      "tensor(2484.1907, device='cuda:0')\n",
      "tensor(2528.5559, device='cuda:0')\n",
      "tensor(2487.3081, device='cuda:0')\n",
      "tensor(2483.0330, device='cuda:0')\n",
      "tensor(2508.2310, device='cuda:0')\n",
      "tensor(2494.5859, device='cuda:0')\n",
      "tensor(2482.9341, device='cuda:0')\n",
      "tensor(2524.4866, device='cuda:0')\n",
      "tensor(2557.1204, device='cuda:0')\n",
      "tensor(2508.2898, device='cuda:0')\n",
      "tensor(2527.4114, device='cuda:0')\n",
      "tensor(2456.9048, device='cuda:0')\n",
      "tensor(2507.9456, device='cuda:0')\n",
      "tensor(2499.9231, device='cuda:0')\n",
      "tensor(2522.3342, device='cuda:0')\n",
      "tensor(2523.6580, device='cuda:0')\n",
      "tensor(2532.7393, device='cuda:0')\n",
      "tensor(2511.3572, device='cuda:0')\n",
      "tensor(2563.9587, device='cuda:0')\n",
      "tensor(2515.8376, device='cuda:0')\n",
      "tensor(2458.1609, device='cuda:0')\n",
      "tensor(2510.6895, device='cuda:0')\n",
      "tensor(2574.8220, device='cuda:0')\n",
      "tensor(2497.5007, device='cuda:0')\n",
      "tensor(2490.2334, device='cuda:0')\n",
      "tensor(2519.4119, device='cuda:0')\n",
      "tensor(2487.8796, device='cuda:0')\n",
      "tensor(2510.3064, device='cuda:0')\n",
      "tensor(2483.0452, device='cuda:0')\n",
      "tensor(2494.2292, device='cuda:0')\n",
      "tensor(2503.8254, device='cuda:0')\n",
      "tensor(2484.2090, device='cuda:0')\n",
      "tensor(2561.7705, device='cuda:0')\n",
      "tensor(2486.9575, device='cuda:0')\n",
      "tensor(2523.8481, device='cuda:0')\n",
      "tensor(2532.6885, device='cuda:0')\n",
      "tensor(2535.8311, device='cuda:0')\n",
      "tensor(2537.3887, device='cuda:0')\n",
      "tensor(2502.1140, device='cuda:0')\n",
      "tensor(2489.8835, device='cuda:0')\n",
      "tensor(2547.6357, device='cuda:0')\n",
      "tensor(2522.0950, device='cuda:0')\n",
      "tensor(2465.0481, device='cuda:0')\n",
      "tensor(2453.3792, device='cuda:0')\n",
      "tensor(2491.5647, device='cuda:0')\n",
      "tensor(2488.1707, device='cuda:0')\n",
      "tensor(2480.7756, device='cuda:0')\n",
      "tensor(2474.5879, device='cuda:0')\n",
      "tensor(2483.9563, device='cuda:0')\n",
      "tensor(2499.2251, device='cuda:0')\n",
      "tensor(2466.7446, device='cuda:0')\n",
      "tensor(2491.2708, device='cuda:0')\n",
      "tensor(2505.9824, device='cuda:0')\n",
      "tensor(2497.2688, device='cuda:0')\n",
      "tensor(2548.3774, device='cuda:0')\n",
      "tensor(2536.6904, device='cuda:0')\n",
      "tensor(2499.4761, device='cuda:0')\n",
      "tensor(2452.1870, device='cuda:0')\n",
      "tensor(2571.4722, device='cuda:0')\n",
      "tensor(2502.3484, device='cuda:0')\n",
      "tensor(2510.0020, device='cuda:0')\n",
      "tensor(2516.7529, device='cuda:0')\n",
      "tensor(2516.9614, device='cuda:0')\n",
      "tensor(2510.8586, device='cuda:0')\n",
      "tensor(2491.6309, device='cuda:0')\n",
      "tensor(2499.5452, device='cuda:0')\n",
      "tensor(2509.4917, device='cuda:0')\n",
      "tensor(2517.9304, device='cuda:0')\n",
      "tensor(2463.8958, device='cuda:0')\n",
      "tensor(2483.5391, device='cuda:0')\n",
      "tensor(2534.5378, device='cuda:0')\n",
      "tensor(2510.4517, device='cuda:0')\n",
      "tensor(2529.2986, device='cuda:0')\n",
      "tensor(2498.2981, device='cuda:0')\n",
      "tensor(2498.7009, device='cuda:0')\n",
      "tensor(2512.4761, device='cuda:0')\n",
      "tensor(2533.7556, device='cuda:0')\n",
      "tensor(2522.7688, device='cuda:0')\n",
      "tensor(2539.9607, device='cuda:0')\n",
      "tensor(2437.1523, device='cuda:0')\n",
      "tensor(2488.5413, device='cuda:0')\n",
      "tensor(2510.1484, device='cuda:0')\n",
      "tensor(2492.1863, device='cuda:0')\n",
      "tensor(2532.5178, device='cuda:0')\n",
      "tensor(2511.8777, device='cuda:0')\n",
      "tensor(2542.0391, device='cuda:0')\n",
      "tensor(2483.5425, device='cuda:0')\n",
      "tensor(2496.4329, device='cuda:0')\n",
      "tensor(2490.8916, device='cuda:0')\n",
      "tensor(2500.6328, device='cuda:0')\n",
      "tensor(2494.1438, device='cuda:0')\n",
      "tensor(2514.5940, device='cuda:0')\n",
      "tensor(2494.0298, device='cuda:0')\n",
      "tensor(2479.5139, device='cuda:0')\n",
      "tensor(2543.5056, device='cuda:0')\n",
      "tensor(2488.0618, device='cuda:0')\n",
      "tensor(2502.5479, device='cuda:0')\n",
      "tensor(2538.6064, device='cuda:0')\n",
      "tensor(2514.4458, device='cuda:0')\n",
      "tensor(2493.9417, device='cuda:0')\n",
      "tensor(2479.3757, device='cuda:0')\n",
      "tensor(2487.3127, device='cuda:0')\n",
      "tensor(2528.4607, device='cuda:0')\n",
      "tensor(2460.4231, device='cuda:0')\n",
      "tensor(2485.1934, device='cuda:0')\n",
      "tensor(2483.8103, device='cuda:0')\n",
      "tensor(2554.2061, device='cuda:0')\n",
      "tensor(2508.5217, device='cuda:0')\n",
      "tensor(2471.8032, device='cuda:0')\n",
      "tensor(2483.8794, device='cuda:0')\n",
      "tensor(2481.1799, device='cuda:0')\n",
      "tensor(2504.0410, device='cuda:0')\n",
      "tensor(2434.8289, device='cuda:0')\n",
      "tensor(2508.6619, device='cuda:0')\n",
      "tensor(2523.5605, device='cuda:0')\n",
      "tensor(2506.3862, device='cuda:0')\n",
      "tensor(2500.5361, device='cuda:0')\n",
      "tensor(2537.6997, device='cuda:0')\n",
      "tensor(2516.4395, device='cuda:0')\n",
      "tensor(2536.0764, device='cuda:0')\n",
      "tensor(2546.3169, device='cuda:0')\n",
      "tensor(2482.8589, device='cuda:0')\n",
      "tensor(2503.2549, device='cuda:0')\n",
      "tensor(2509.5864, device='cuda:0')\n",
      "tensor(2528.3279, device='cuda:0')\n",
      "tensor(2517.0378, device='cuda:0')\n",
      "tensor(2533.3745, device='cuda:0')\n",
      "tensor(2450.9050, device='cuda:0')\n",
      "tensor(2542.0645, device='cuda:0')\n",
      "tensor(2502.3608, device='cuda:0')\n",
      "tensor(2502.0696, device='cuda:0')\n",
      "tensor(2563.0544, device='cuda:0')\n",
      "tensor(2526.1260, device='cuda:0')\n",
      "tensor(2523.3599, device='cuda:0')\n",
      "tensor(2473.6423, device='cuda:0')\n",
      "tensor(2539.9465, device='cuda:0')\n",
      "tensor(2512.3528, device='cuda:0')\n",
      "tensor(2527.7302, device='cuda:0')\n",
      "tensor(2509.6006, device='cuda:0')\n",
      "tensor(2514.6028, device='cuda:0')\n",
      "tensor(2536.6218, device='cuda:0')\n",
      "tensor(2541.2339, device='cuda:0')\n",
      "tensor(2512.5977, device='cuda:0')\n",
      "tensor(2436.6624, device='cuda:0')\n",
      "tensor(2502.3804, device='cuda:0')\n",
      "tensor(2478.5166, device='cuda:0')\n",
      "tensor(2515.5388, device='cuda:0')\n",
      "tensor(2504.3020, device='cuda:0')\n",
      "tensor(2504.4241, device='cuda:0')\n",
      "tensor(2527.6882, device='cuda:0')\n",
      "tensor(2513.6331, device='cuda:0')\n",
      "tensor(2499.0938, device='cuda:0')\n",
      "tensor(2515.6650, device='cuda:0')\n",
      "tensor(2501.9390, device='cuda:0')\n",
      "tensor(2495.1919, device='cuda:0')\n",
      "tensor(2577.9399, device='cuda:0')\n",
      "tensor(2510.2070, device='cuda:0')\n",
      "tensor(2546.7500, device='cuda:0')\n",
      "tensor(2505.9736, device='cuda:0')\n",
      "tensor(2522.8699, device='cuda:0')\n",
      "tensor(2512.3467, device='cuda:0')\n",
      "tensor(2496.2642, device='cuda:0')\n",
      "tensor(2505.1343, device='cuda:0')\n",
      "tensor(2515.2500, device='cuda:0')\n",
      "tensor(2488.6902, device='cuda:0')\n",
      "tensor(2528.1353, device='cuda:0')\n",
      "tensor(2485.6111, device='cuda:0')\n",
      "tensor(2561.6394, device='cuda:0')\n",
      "tensor(2488.5269, device='cuda:0')\n",
      "tensor(2524.5674, device='cuda:0')\n",
      "tensor(2518.8723, device='cuda:0')\n",
      "tensor(2517.4766, device='cuda:0')\n",
      "tensor(2538.3418, device='cuda:0')\n",
      "tensor(2517.0154, device='cuda:0')\n",
      "tensor(2492.6284, device='cuda:0')\n",
      "tensor(2526.2241, device='cuda:0')\n",
      "tensor(2508.2830, device='cuda:0')\n",
      "tensor(2535.7966, device='cuda:0')\n",
      "tensor(2527.6851, device='cuda:0')\n",
      "tensor(2528.4905, device='cuda:0')\n",
      "tensor(2482.8093, device='cuda:0')\n",
      "tensor(2493.8584, device='cuda:0')\n",
      "tensor(2471.6553, device='cuda:0')\n",
      "tensor(2527.6194, device='cuda:0')\n",
      "tensor(2499.8811, device='cuda:0')\n",
      "tensor(2524.6130, device='cuda:0')\n",
      "tensor(2486.0361, device='cuda:0')\n",
      "tensor(2524.5154, device='cuda:0')\n",
      "tensor(2594.0188, device='cuda:0')\n",
      "tensor(2528.8706, device='cuda:0')\n",
      "tensor(2514.7009, device='cuda:0')\n",
      "tensor(2506.0354, device='cuda:0')\n",
      "tensor(2483.7573, device='cuda:0')\n",
      "tensor(2482.8926, device='cuda:0')\n",
      "tensor(2509.0300, device='cuda:0')\n",
      "tensor(2474.7471, device='cuda:0')\n",
      "tensor(2532.6450, device='cuda:0')\n",
      "tensor(2503.5354, device='cuda:0')\n",
      "tensor(2481.7329, device='cuda:0')\n",
      "tensor(2513.1482, device='cuda:0')\n",
      "tensor(2466.4463, device='cuda:0')\n",
      "tensor(2480.0637, device='cuda:0')\n",
      "tensor(2490.3735, device='cuda:0')\n",
      "tensor(2513.8748, device='cuda:0')\n",
      "tensor(2507.5601, device='cuda:0')\n",
      "tensor(2511.8235, device='cuda:0')\n",
      "tensor(2511.1216, device='cuda:0')\n",
      "tensor(2549.0940, device='cuda:0')\n",
      "tensor(2479.6257, device='cuda:0')\n",
      "tensor(2510.6096, device='cuda:0')\n",
      "tensor(2512.4265, device='cuda:0')\n",
      "tensor(2522.6602, device='cuda:0')\n",
      "tensor(2589.4158, device='cuda:0')\n",
      "tensor(2460.4905, device='cuda:0')\n",
      "tensor(2491.7529, device='cuda:0')\n",
      "tensor(2524.6211, device='cuda:0')\n",
      "tensor(2491.7556, device='cuda:0')\n",
      "tensor(2492.2720, device='cuda:0')\n",
      "tensor(2553.3875, device='cuda:0')\n",
      "tensor(2503.5754, device='cuda:0')\n",
      "tensor(2461.8525, device='cuda:0')\n",
      "tensor(2489.0708, device='cuda:0')\n",
      "tensor(2501.9873, device='cuda:0')\n",
      "tensor(2550.2363, device='cuda:0')\n",
      "tensor(2495.2776, device='cuda:0')\n",
      "tensor(2550.5522, device='cuda:0')\n",
      "tensor(2471.1648, device='cuda:0')\n",
      "tensor(2498.3943, device='cuda:0')\n",
      "tensor(2490.3137, device='cuda:0')\n",
      "tensor(2500.8765, device='cuda:0')\n",
      "tensor(2533.9194, device='cuda:0')\n",
      "tensor(2508.7488, device='cuda:0')\n",
      "tensor(2528.5754, device='cuda:0')\n",
      "tensor(2489.7759, device='cuda:0')\n",
      "tensor(2459.7329, device='cuda:0')\n",
      "tensor(2573.2078, device='cuda:0')\n",
      "tensor(2523.9316, device='cuda:0')\n",
      "tensor(2538.0728, device='cuda:0')\n",
      "tensor(2522.7517, device='cuda:0')\n",
      "tensor(2542.7344, device='cuda:0')\n",
      "tensor(2497.8728, device='cuda:0')\n",
      "tensor(2503.9370, device='cuda:0')\n",
      "tensor(2504.6716, device='cuda:0')\n",
      "tensor(2497.4724, device='cuda:0')\n",
      "tensor(2505.6682, device='cuda:0')\n",
      "tensor(2552.6194, device='cuda:0')\n",
      "tensor(2549.6616, device='cuda:0')\n",
      "tensor(2491.1372, device='cuda:0')\n",
      "tensor(2553.8584, device='cuda:0')\n",
      "tensor(2512.2332, device='cuda:0')\n",
      "tensor(2490.0496, device='cuda:0')\n",
      "tensor(2512.4265, device='cuda:0')\n",
      "tensor(2543.6624, device='cuda:0')\n",
      "tensor(2514.3477, device='cuda:0')\n",
      "tensor(2525.1663, device='cuda:0')\n",
      "tensor(2532.9749, device='cuda:0')\n",
      "tensor(2532.7070, device='cuda:0')\n",
      "tensor(2529.7925, device='cuda:0')\n",
      "tensor(2503.0671, device='cuda:0')\n",
      "tensor(2499.9194, device='cuda:0')\n",
      "tensor(2460.9971, device='cuda:0')\n",
      "tensor(2521.0417, device='cuda:0')\n",
      "tensor(2500.1475, device='cuda:0')\n",
      "tensor(2507.9998, device='cuda:0')\n",
      "tensor(2579.0645, device='cuda:0')\n",
      "tensor(2498.7212, device='cuda:0')\n",
      "tensor(2543.4937, device='cuda:0')\n",
      "tensor(2517.7971, device='cuda:0')\n",
      "tensor(2505.8130, device='cuda:0')\n",
      "tensor(2511.9182, device='cuda:0')\n",
      "tensor(2527.5801, device='cuda:0')\n",
      "tensor(2509.7271, device='cuda:0')\n",
      "tensor(2451.9941, device='cuda:0')\n",
      "tensor(2494.0215, device='cuda:0')\n",
      "tensor(2535.7952, device='cuda:0')\n",
      "tensor(2498.5457, device='cuda:0')\n",
      "tensor(2538.8352, device='cuda:0')\n",
      "tensor(2504.4263, device='cuda:0')\n",
      "tensor(2500.4749, device='cuda:0')\n",
      "tensor(2496.6921, device='cuda:0')\n",
      "tensor(2475.6287, device='cuda:0')\n",
      "tensor(2514.2209, device='cuda:0')\n",
      "tensor(2466.2947, device='cuda:0')\n",
      "tensor(2493.4636, device='cuda:0')\n",
      "tensor(2506.3521, device='cuda:0')\n",
      "tensor(2477.5466, device='cuda:0')\n",
      "tensor(2540.3560, device='cuda:0')\n",
      "tensor(2446.5410, device='cuda:0')\n",
      "tensor(2521.0071, device='cuda:0')\n",
      "tensor(2556.6768, device='cuda:0')\n",
      "tensor(2507.1572, device='cuda:0')\n",
      "tensor(2474.5884, device='cuda:0')\n",
      "tensor(2565.0300, device='cuda:0')\n",
      "tensor(2493.0994, device='cuda:0')\n",
      "tensor(2518.2058, device='cuda:0')\n",
      "tensor(2476.2688, device='cuda:0')\n",
      "tensor(2492.1030, device='cuda:0')\n",
      "tensor(2520.7927, device='cuda:0')\n",
      "tensor(2496.8862, device='cuda:0')\n",
      "tensor(2491.3071, device='cuda:0')\n",
      "tensor(2471.0247, device='cuda:0')\n",
      "tensor(2548.5437, device='cuda:0')\n",
      "tensor(2458.6069, device='cuda:0')\n",
      "tensor(2512.9792, device='cuda:0')\n",
      "tensor(2543.5249, device='cuda:0')\n",
      "tensor(2497.3000, device='cuda:0')\n",
      "tensor(2504.1897, device='cuda:0')\n",
      "tensor(2524.2698, device='cuda:0')\n",
      "tensor(2546.9712, device='cuda:0')\n",
      "tensor(2518.1399, device='cuda:0')\n",
      "tensor(2488.2585, device='cuda:0')\n",
      "tensor(2503.2769, device='cuda:0')\n",
      "tensor(2522.6528, device='cuda:0')\n",
      "tensor(2504.4761, device='cuda:0')\n",
      "tensor(2501.6001, device='cuda:0')\n",
      "tensor(2464.3320, device='cuda:0')\n",
      "tensor(2565.3906, device='cuda:0')\n",
      "tensor(2482.5688, device='cuda:0')\n",
      "tensor(2516.3086, device='cuda:0')\n",
      "tensor(2489.3479, device='cuda:0')\n",
      "tensor(2523.9426, device='cuda:0')\n",
      "tensor(2554.0947, device='cuda:0')\n",
      "tensor(2493.0837, device='cuda:0')\n",
      "tensor(2484.4028, device='cuda:0')\n",
      "tensor(2496.4036, device='cuda:0')\n",
      "tensor(2558.6670, device='cuda:0')\n",
      "tensor(2472.2551, device='cuda:0')\n",
      "tensor(2519.6763, device='cuda:0')\n",
      "tensor(2523.5549, device='cuda:0')\n",
      "tensor(2491.7656, device='cuda:0')\n",
      "tensor(2450.1687, device='cuda:0')\n",
      "tensor(2469.7085, device='cuda:0')\n",
      "tensor(2461.0127, device='cuda:0')\n",
      "tensor(2502.8950, device='cuda:0')\n",
      "tensor(2496.0923, device='cuda:0')\n",
      "tensor(2521.4167, device='cuda:0')\n",
      "tensor(2458.0969, device='cuda:0')\n",
      "tensor(2519.1792, device='cuda:0')\n",
      "tensor(2454.9299, device='cuda:0')\n",
      "tensor(2458.0200, device='cuda:0')\n",
      "tensor(2518.5818, device='cuda:0')\n",
      "tensor(2537.7632, device='cuda:0')\n",
      "tensor(2487.2739, device='cuda:0')\n",
      "tensor(2487.5356, device='cuda:0')\n",
      "tensor(2518.4109, device='cuda:0')\n",
      "tensor(2539.8574, device='cuda:0')\n",
      "tensor(2513.8884, device='cuda:0')\n",
      "tensor(2505.7729, device='cuda:0')\n",
      "tensor(2544.2476, device='cuda:0')\n",
      "tensor(2501.3464, device='cuda:0')\n",
      "tensor(2494.1975, device='cuda:0')\n",
      "tensor(2486.1726, device='cuda:0')\n",
      "tensor(2518.3838, device='cuda:0')\n",
      "tensor(2512.7751, device='cuda:0')\n",
      "tensor(2504.1516, device='cuda:0')\n",
      "tensor(2516.5312, device='cuda:0')\n",
      "tensor(2490.7314, device='cuda:0')\n",
      "tensor(2497.0134, device='cuda:0')\n",
      "tensor(2514.8572, device='cuda:0')\n",
      "tensor(2458.3948, device='cuda:0')\n",
      "tensor(2467.8318, device='cuda:0')\n",
      "tensor(2505.4941, device='cuda:0')\n",
      "tensor(2495.4614, device='cuda:0')\n",
      "tensor(2496.2039, device='cuda:0')\n",
      "tensor(2473.5322, device='cuda:0')\n",
      "tensor(2508.6731, device='cuda:0')\n",
      "tensor(2505.7805, device='cuda:0')\n",
      "tensor(2465.7161, device='cuda:0')\n",
      "tensor(2522.0876, device='cuda:0')\n",
      "tensor(2546.0630, device='cuda:0')\n",
      "tensor(2550.7666, device='cuda:0')\n",
      "tensor(2524.2126, device='cuda:0')\n",
      "tensor(2490.3696, device='cuda:0')\n",
      "tensor(2455.4917, device='cuda:0')\n",
      "tensor(2563.7754, device='cuda:0')\n",
      "tensor(2447.1509, device='cuda:0')\n",
      "tensor(2520.0486, device='cuda:0')\n",
      "tensor(2493.7544, device='cuda:0')\n",
      "tensor(2504.9260, device='cuda:0')\n",
      "tensor(2558.8601, device='cuda:0')\n",
      "tensor(2512.0891, device='cuda:0')\n",
      "tensor(2488.3418, device='cuda:0')\n",
      "tensor(2547.8733, device='cuda:0')\n",
      "tensor(2528.1716, device='cuda:0')\n",
      "tensor(2521.9207, device='cuda:0')\n",
      "tensor(2536.9702, device='cuda:0')\n",
      "tensor(2484.1628, device='cuda:0')\n",
      "tensor(2531.1877, device='cuda:0')\n",
      "tensor(2516.2974, device='cuda:0')\n",
      "tensor(2522.3735, device='cuda:0')\n",
      "tensor(2467.1201, device='cuda:0')\n",
      "tensor(2554.4509, device='cuda:0')\n",
      "tensor(2469.4780, device='cuda:0')\n",
      "tensor(2504.9075, device='cuda:0')\n",
      "tensor(2509.1528, device='cuda:0')\n",
      "tensor(2473.7817, device='cuda:0')\n",
      "tensor(2524.9143, device='cuda:0')\n",
      "tensor(2469.2759, device='cuda:0')\n",
      "tensor(2515.4121, device='cuda:0')\n",
      "tensor(2525.0901, device='cuda:0')\n",
      "tensor(2520.2134, device='cuda:0')\n",
      "tensor(2493.0200, device='cuda:0')\n",
      "tensor(2520.1064, device='cuda:0')\n",
      "tensor(2506.3438, device='cuda:0')\n",
      "tensor(2510.2820, device='cuda:0')\n",
      "tensor(2491.2791, device='cuda:0')\n",
      "tensor(2481.1296, device='cuda:0')\n",
      "tensor(2480.3643, device='cuda:0')\n",
      "tensor(2528.9238, device='cuda:0')\n",
      "tensor(2515.6208, device='cuda:0')\n",
      "tensor(2512.1255, device='cuda:0')\n",
      "tensor(2497.7917, device='cuda:0')\n",
      "tensor(2512.6667, device='cuda:0')\n",
      "tensor(2491.3213, device='cuda:0')\n",
      "tensor(2559.1951, device='cuda:0')\n",
      "tensor(2535.3257, device='cuda:0')\n",
      "tensor(2496.0549, device='cuda:0')\n",
      "tensor(2477.0669, device='cuda:0')\n",
      "tensor(2500.9260, device='cuda:0')\n",
      "tensor(2479.2510, device='cuda:0')\n",
      "tensor(2552.2827, device='cuda:0')\n",
      "tensor(2535.0828, device='cuda:0')\n",
      "tensor(2572.3088, device='cuda:0')\n",
      "tensor(2484.2998, device='cuda:0')\n",
      "tensor(2534.3159, device='cuda:0')\n",
      "tensor(2526.3516, device='cuda:0')\n",
      "tensor(2495.7974, device='cuda:0')\n",
      "tensor(2500.3293, device='cuda:0')\n",
      "tensor(2533.9016, device='cuda:0')\n",
      "tensor(2534.1028, device='cuda:0')\n",
      "tensor(2568.7065, device='cuda:0')\n",
      "tensor(2522.1138, device='cuda:0')\n",
      "tensor(2543.2668, device='cuda:0')\n",
      "tensor(2553.8438, device='cuda:0')\n",
      "tensor(2514.7451, device='cuda:0')\n",
      "tensor(2557.2185, device='cuda:0')\n",
      "tensor(2508.5173, device='cuda:0')\n",
      "tensor(2585.8442, device='cuda:0')\n",
      "tensor(2504.6672, device='cuda:0')\n",
      "tensor(2470.8643, device='cuda:0')\n",
      "tensor(2474.7942, device='cuda:0')\n",
      "tensor(2493.7927, device='cuda:0')\n",
      "tensor(2482.6233, device='cuda:0')\n",
      "tensor(2483.7334, device='cuda:0')\n",
      "tensor(2522.0459, device='cuda:0')\n",
      "tensor(2485.5339, device='cuda:0')\n",
      "tensor(2539.9414, device='cuda:0')\n",
      "tensor(2520.9309, device='cuda:0')\n",
      "tensor(2533.9009, device='cuda:0')\n",
      "tensor(2482.5044, device='cuda:0')\n",
      "tensor(2512.9409, device='cuda:0')\n",
      "tensor(2558.4919, device='cuda:0')\n",
      "tensor(2517.7759, device='cuda:0')\n",
      "tensor(2513.0591, device='cuda:0')\n",
      "tensor(2506.4985, device='cuda:0')\n",
      "tensor(2497.9194, device='cuda:0')\n",
      "tensor(2537.5850, device='cuda:0')\n",
      "tensor(2497.3999, device='cuda:0')\n",
      "tensor(2490.2336, device='cuda:0')\n",
      "tensor(2549.3025, device='cuda:0')\n",
      "tensor(2480.2605, device='cuda:0')\n",
      "tensor(2484.5144, device='cuda:0')\n",
      "tensor(2576.9614, device='cuda:0')\n",
      "tensor(2558.7598, device='cuda:0')\n",
      "tensor(2537.7080, device='cuda:0')\n",
      "tensor(2496.7656, device='cuda:0')\n",
      "tensor(2490.4229, device='cuda:0')\n",
      "tensor(2493.8735, device='cuda:0')\n",
      "tensor(2519.7063, device='cuda:0')\n",
      "tensor(2463.3704, device='cuda:0')\n",
      "tensor(2561.6130, device='cuda:0')\n",
      "tensor(2552.1062, device='cuda:0')\n",
      "tensor(2527.0413, device='cuda:0')\n",
      "tensor(2526.1736, device='cuda:0')\n",
      "tensor(2552.2451, device='cuda:0')\n",
      "tensor(2551.8149, device='cuda:0')\n",
      "tensor(2476.0999, device='cuda:0')\n",
      "tensor(2532.1980, device='cuda:0')\n",
      "tensor(2507.8457, device='cuda:0')\n",
      "tensor(2519.7043, device='cuda:0')\n",
      "tensor(2503.5752, device='cuda:0')\n",
      "tensor(2472.9690, device='cuda:0')\n",
      "tensor(2462.1758, device='cuda:0')\n",
      "tensor(2555.1846, device='cuda:0')\n",
      "tensor(2497.8564, device='cuda:0')\n",
      "tensor(2529.4495, device='cuda:0')\n",
      "tensor(2553.3325, device='cuda:0')\n",
      "tensor(2489.2124, device='cuda:0')\n",
      "tensor(2483.0281, device='cuda:0')\n",
      "tensor(2549.2705, device='cuda:0')\n",
      "tensor(2510.4043, device='cuda:0')\n",
      "tensor(2543.2085, device='cuda:0')\n",
      "tensor(2476.2288, device='cuda:0')\n",
      "tensor(2525.8540, device='cuda:0')\n",
      "tensor(2522.8525, device='cuda:0')\n",
      "tensor(2509.1853, device='cuda:0')\n",
      "tensor(2498.3274, device='cuda:0')\n",
      "tensor(2526.4929, device='cuda:0')\n",
      "tensor(2531.5693, device='cuda:0')\n",
      "tensor(2559.2454, device='cuda:0')\n",
      "tensor(2483.2517, device='cuda:0')\n",
      "tensor(2487.1228, device='cuda:0')\n",
      "tensor(2536.3142, device='cuda:0')\n",
      "tensor(2495.3047, device='cuda:0')\n",
      "tensor(2496.1609, device='cuda:0')\n",
      "tensor(2540.9507, device='cuda:0')\n",
      "tensor(2484.2786, device='cuda:0')\n",
      "tensor(2482.5054, device='cuda:0')\n",
      "tensor(2493.7029, device='cuda:0')\n",
      "tensor(2532.5425, device='cuda:0')\n",
      "tensor(2554.0327, device='cuda:0')\n",
      "tensor(2538.6882, device='cuda:0')\n",
      "tensor(2511.3718, device='cuda:0')\n",
      "tensor(2519.1501, device='cuda:0')\n",
      "tensor(2550.8394, device='cuda:0')\n",
      "tensor(2472.2637, device='cuda:0')\n",
      "tensor(2503.0938, device='cuda:0')\n",
      "tensor(2541.4006, device='cuda:0')\n",
      "tensor(2505.7673, device='cuda:0')\n",
      "tensor(2498.6030, device='cuda:0')\n",
      "tensor(2486.6421, device='cuda:0')\n",
      "tensor(2505.6855, device='cuda:0')\n",
      "tensor(2548.3660, device='cuda:0')\n",
      "tensor(2535.8018, device='cuda:0')\n",
      "Time taken: 0.9877846240997314\n",
      "实验一消耗时间：0.04256129264831543，实验二消耗时间：0.9877846240997314\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "matrics = [torch.rand((100, 100)).to(device) for _ in range(1000)]\n",
    "\n",
    "# 实验一\n",
    "start_time_1 = time.time()\n",
    "for i in range(1000):\n",
    "    result = torch.mm(matrics[i], matrics[i].t()) # 不转置也无所谓\n",
    "    forbenius_norm = torch.norm(result)    \n",
    "end_time_1 = time.time()\n",
    "print('Time taken:', end_time_1 - start_time_1)\n",
    "\n",
    "\n",
    "# 实验二\n",
    "start_time_2 = time.time()\n",
    "for i in range(1000):\n",
    "    result = torch.mm(matrics[i], matrics[i])\n",
    "    forbenius_norm = torch.norm(result)\n",
    "    print(forbenius_norm)\n",
    "end_time_2 = time.time()\n",
    "print('Time taken:', end_time_2 - start_time_2)\n",
    "\n",
    "print(f'实验一消耗时间：{end_time_1 - start_time_1}，实验二消耗时间：{end_time_2 - start_time_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ce8727-2847-4e3c-8983-f8471057dbdd",
   "metadata": {},
   "source": [
    "4. 测量同时在两个GPU上执行两个矩阵乘法与在一个GPU上按顺序执行两个矩阵乘法所需的时间。提示：应该看到近乎线性的缩放。\n",
    "- 执行两个矩阵乘法并行在两个GPU上所需要的时间 通常**小的多**比 在单个GPU上岸顺序执行两个矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d96efcbc-8f7e-4e80-89e0-b16ed9dabdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0ms\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "a = torch.randn(1000, 1000).cuda()\n",
    "b = torch.randn(1000, 1000).cuda()\n",
    "\n",
    "start_time = time.time()\n",
    "torch.mm(a, b)\n",
    "torch.mm(a, b)\n",
    "end_time = time.time()\n",
    "sequential_time =end_time - start_time\n",
    "print(f'{sequential_time * 1000}ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0be33de-9b79-451a-ac4f-51a69ce737d5",
   "metadata": {},
   "source": [
    "`torch.cuda.synchronize()`常用于需要精确测量GPU计算时间的场合\n",
    "- 频繁调用`torch.cuda.synchronize()`会导致性能下降，尤其是不必要时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23fd50e-7f44-44af-9f44-68cb1b94695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "if torch.cuda.device_count() < 2:\n",
    "    print('需要至少2个GPU来运行此代码')\n",
    "else:\n",
    "    size = (1000, 1000)\n",
    "    \n",
    "# 串行\n",
    "device0 = torch.device('cude:0')\n",
    "a1 = torch.rand(size, device=device0)\n",
    "b1 = torch.rand(size, device=device0)\n",
    "\n",
    "start_time = time.time()\n",
    "c1 = torch.matmul(a1, b1)\n",
    "torch.cude.synchronize(device0)\n",
    "\n",
    "c2 = torch.matmul(a1, b1)\n",
    "torch.cude.synchronize(device0)\n",
    "sequential_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# 并行\n",
    "device1 = torch.device('cuda:1')\n",
    "A2 = torch.rand(size, device=device0)\n",
    "B2 = torch.rand(size, device=device0)\n",
    "A3 = torch.rand(size, device=device1)\n",
    "B3 = torch.rand(size, device=device1)\n",
    "\n",
    "start_time = time.time()\n",
    "C3 = torch.matmul(A2, B2)\n",
    "C4 = torch.matmul(A3, B3)\n",
    "torch.cuda.synchronize(device0)\n",
    "torch.cuda.synchronize(device1)\n",
    "parallel_time = time.time() - start_time\n",
    "\n",
    "print(f\"双 GPU 并行执行时间: {parallel_time:.4f} 秒\")\n",
    "print(f\"速度提升比率（近乎线性）：{speedup:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce10f62b-53d6-4b13-b6f8-b149ea7958c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 28 15:12:54 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 457.49       Driver Version: 457.49       CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce MX150      WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   52C    P0    N/A /  N/A |    580MiB /  2048MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     24328      C   ...\\envs\\fxr_env2\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5342f4c4-0229-44a2-aa3b-b4c607af0c1a",
   "metadata": {},
   "source": [
    "#### **删除变量，释放内存**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6b8d17b-df7f-4ebb-b541-797045ad2f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del a, b\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13756dca-130a-4c87-af0c-7a219deccf82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
